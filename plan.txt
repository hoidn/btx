# Optimization Plan for plot_diagnostics() Bottlenecks

## Bottleneck 1: Frame Concatenation (~27% of runtime)

Current code:
```python
all_frames = np.concatenate([
    np.concatenate([self.stacks_on[d].frames, self.stacks_off[d].frames])
    for d in output.delays
])
```

Problems:
- Creates large temporary arrays
- Requires double concatenation
- Uses excessive memory
- Scales poorly with number of frames

Optimized approach:
```python
total_counts = None
for delay in output.delays:
    frames_on = self.stacks_on[delay].frames
    frames_off = self.stacks_off[delay].frames
    
    if total_counts is None:
        total_counts = np.zeros_like(frames_on[0])
    
    total_counts += np.sum(frames_on, axis=0) + np.sum(frames_off, axis=0)
```

Benefits:
- Constant memory usage
- Single pass through data
- No temporary arrays
- O(n) scaling with frames
- Directly computes needed sum

## Bottleneck 2: Energy Filtering (~19.5% of runtime)

Current code:
```python
energy_mask = self._make_energy_filter(all_frames)
filtered_counts = np.sum(all_frames * energy_mask, axis=0)
```

Problems:
- Applies filter to all frames at once
- Creates large temporary mask array
- Requires full frame array in memory
- Redundant calculations for same energy values

Optimized approach:
```python
filtered_counts = None
for delay in output.delays:
    frames_on = self.stacks_on[delay].frames
    frames_off = self.stacks_off[delay].frames
    
    if filtered_counts is None:
        filtered_counts = np.zeros_like(frames_on[0])
    
    # Apply energy filter in chunks
    energy_mask_on = self._make_energy_filter(frames_on)
    energy_mask_off = self._make_energy_filter(frames_off)
    
    filtered_counts += (np.sum(frames_on * energy_mask_on, axis=0) + 
                       np.sum(frames_off * energy_mask_off, axis=0))
```

Benefits:
- Processes data in chunks
- Constant memory usage
- Can potentially cache masks
- Combines filtering and summing
- No large temporary arrays

## Implementation Steps:

1. Replace frame concatenation with incremental summing
2. Modify energy filtering to work in chunks
3. Add optional mask caching if same energy values repeat
4. Consider adding progress tracking for long operations
5. Add memory usage logging/monitoring
6. Benchmark before/after performance

## Expected Improvements:

- Memory usage: ~70% reduction
- Runtime: ~40% reduction for these sections
- Better scaling with dataset size
- More predictable performance

## Future Optimizations to Consider:

1. Parallel processing for frame accumulation
2. Downsampling frames for visualization
3. Caching energy mask calculations
4. Making detailed diagnostics optional
5. Using memory-mapped arrays for very large datasets
